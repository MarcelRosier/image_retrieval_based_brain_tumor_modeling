
## Intro

- agenda
- introduce topic: 
    - whats it about
    - what exists
    - pipeline -> adapt 
    - what will we change, test

---

## Approach

- Dataset: 
    - syntetic: atlas braina antomy, generated by felix, reaction diffusion model, 50k tumors
    - real test set: MRI scans from TUM
- LMI Pipeline:
    - steps, figure
- Baseline:
    - figure to show adaption
    - naive loop, pairwise iteartive comparison
    - metric? DICE, later L2 norm for encoded data
    - syn tumors continous -> threshold to get segs
    - 2 segs -> combine score
    - parallelize? 
- Compression steps
    - Down sampling: spline interpolation 64 and 32
    - AE:
        - (expanation probably redundant)
        - explain idea: problem-specific encoding maybe able to preserve similarity relationships
        - Neural network: architecture
        - Training: 
            - table with parameters
            - mention latent space comp?
            - final losses for T1Gd and FLAIR
    - VAE:
        - shortly explain idea: latent space most relevant, test if more organized is valuebale for sim preservation
        - adaptions to network
        - training results
        - mention alte founds improvs: 
            - loss alone can not describe similarit relationships
            - larger latent spaces do provide sim pres benefits
            - larger TS as well

## Evaluation

- Quantitative:
    - Explain metrics
    - Baseline:
        - best match dices for real AND syn data
        - discuss applicability -> more realsitc dataset might be better
    - Compression:
        - apply all appraoches and evaluate best match
        - show table
- Qualititative:
    - Test set of qual eval tumors, explain how chosen (dice + bm pres), table?
    - show 3d figure, discuss flair weighting? 
    - AE and vAE recosntruction capabilites ? needed?
- LMI emebdding
    - figure, discuss

## Future work

- improve dataset
- improve methods
- try sim preserving encoding
- try sim preserving hashing

## Conclusion
- query appraoch could be useful
- deep learning methods can encode similarity relationships up to a certain degree
